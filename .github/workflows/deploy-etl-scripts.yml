
name: Pyspark ETL Script Deploy 
on: workflow_dispatch
jobs:
  script-copy:
    runs-on: self-hosted
    steps:
    - uses: actions/checkout@v1
 
    - name: Copy ETL to Spark Cluster 
      run: |
        docker cp ./scripts/. airflow-spark-spark-worker-1:/opt/bitnami/spark/dev/scripts
        docker cp ./scripts/. airflow-spark-spark-worker-2:/opt/bitnami/spark/dev/scripts
        docker cp ./scripts/. airflow-spark-spark-worker-3:/opt/bitnami/spark/dev/scripts
